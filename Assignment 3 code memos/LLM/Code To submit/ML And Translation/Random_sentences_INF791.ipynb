{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Creating random corpus sentences for testing of translation**"
      ],
      "metadata": {
        "id": "yRxUQAnsxogW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJbuRzUthzgk",
        "outputId": "f4e6f2c3-792d-411d-e0da-4a1e4f3a014c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  source_language                                      sentence\n",
            "0          CILUBA      umue kutela kukanga kusumba kushindikija\n",
            "1          CILUBA                  Ne Kudima cilenga Diata Lala\n",
            "2          CILUBA                Biabunyi kuja Menyi Tshia Kuya\n",
            "3          CILUBA        bungi kuata kupandisha kubueja kunyema\n",
            "4          CILUBA  dilekela cyomò Bueja mudilu TshipepeleButoke\n",
            "  source_language                                           sentence\n",
            "0          FRENCH               un tempête arranger plein superposer\n",
            "1          FRENCH                 une cille epaule xylophone atacher\n",
            "2          FRENCH  beaucoup tranquillité exhortation cheville inv...\n",
            "3          FRENCH         beaucoup oreiller provoquer visiter courir\n",
            "4          FRENCH  abandon infirmier recevoir mettredansunechose ...\n",
            "  source_language                                sentence\n",
            "0         ENGLISH        a weakness derogate pray look at\n",
            "1         ENGLISH            a propagate failure right on\n",
            "2         ENGLISH  a lot misery wicked gravitate repeated\n",
            "3         ENGLISH      a lot branch world accept quantity\n",
            "4         ENGLISH   abandonment satisfaction rice cup hit\n",
            "  source_language                                   sentence\n",
            "0       AFRIKAANS             n voorkoms As plaatmetaal vier\n",
            "1       AFRIKAANS            'n gaan sit Vroue oor aangenaam\n",
            "2       AFRIKAANS           baie vrugbaar wieg Slaag Woestyn\n",
            "3       AFRIKAANS  baie Mukolabibi Woensdag aanhouding hamer\n",
            "4       AFRIKAANS            Verlating Been Nek smeking Seks\n",
            "  source_language                                           sentence\n",
            "0            ZULU  I esitofusanalahle Ngokuphangi landa amashumi ...\n",
            "1            ZULU                  I ubumpofu ukuzwa khempa isiphuzo\n",
            "2            ZULU         okuningi isikhwama isigqoko Hlala Njengoba\n",
            "3            ZULU          okuningi isicelo ubulima Inhlawulo nisela\n",
            "4            ZULU  Ukulahlwa ukuqhubekela phambili Ingwenya kweny...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/corrected_lexicon.xlsx'\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data from the first sheet\n",
        "df = pd.read_excel(excel_data)\n",
        "\n",
        "# Extracting the relevant columns for each language to create individual dataframes\n",
        "languages = ['CILUBA', 'FRANCAIS', 'ENGLISH', 'AFRIKAANS', 'ZULU']\n",
        "\n",
        "# Creating individual dataframes for each language along with their nature\n",
        "df_ciluba = df[['CILUBA', 'NATURE']].dropna().rename(columns={'CILUBA': 'word'})\n",
        "df_french = df[['FRANCAIS', 'NATURE']].dropna().rename(columns={'FRANCAIS': 'word'})\n",
        "df_english = df[['ENGLISH', 'NATURE']].dropna().rename(columns={'ENGLISH': 'word'})\n",
        "df_afrikaans = df[['AFRIKAANS', 'NATURE']].dropna().rename(columns={'AFRIKAANS': 'word'})\n",
        "df_zulu = df[['ZULU', 'NATURE']].dropna().rename(columns={'ZULU': 'word'})\n",
        "\n",
        "def create_random_sentences(df, language_name):\n",
        "    \"\"\"\n",
        "    This function takes a dataframe of words and their nature and creates a new dataframe with randomized sentences.\n",
        "    The sentences consist of the word in the current row and 4 randomly selected words from the dataframe.\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "\n",
        "    # Convert the 'word' column to a list for random selection\n",
        "    words_list = df['word'].str.strip().tolist()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Get the current word\n",
        "        current_word = row['word'].strip()\n",
        "\n",
        "        # Randomly select 4 other words from the list\n",
        "        random_words = random.choices(words_list, k=4)\n",
        "\n",
        "        # Create the sentence\n",
        "        sentence = ' '.join([current_word] + random_words)\n",
        "\n",
        "        # Append the sentence and source language to the list\n",
        "        sentences.append({'source_language': language_name, 'sentence': sentence})\n",
        "\n",
        "    # Create a new dataframe from the list of sentences\n",
        "    sentences_df = pd.DataFrame(sentences)\n",
        "    return sentences_df\n",
        "\n",
        "# Creating the randomized sentence dataframe for each language\n",
        "df_ciluba_sentences = create_random_sentences(df_ciluba, 'CILUBA')\n",
        "df_french_sentences = create_random_sentences(df_french, 'FRENCH')\n",
        "df_english_sentences = create_random_sentences(df_english, 'ENGLISH')\n",
        "df_afrikaans_sentences = create_random_sentences(df_afrikaans, 'AFRIKAANS')\n",
        "df_zulu_sentences = create_random_sentences(df_zulu, 'ZULU')\n",
        "\n",
        "# Display the first 5 rows of each dataframe\n",
        "print(df_ciluba_sentences.head(5))\n",
        "print(df_french_sentences.head(5))\n",
        "print(df_english_sentences.head(5))\n",
        "print(df_afrikaans_sentences.head(5))\n",
        "print(df_zulu_sentences.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Function to save each dataframe as an Excel file\n",
        "def save_and_download(dataframe, filename):\n",
        "    \"\"\"\n",
        "    Saves a given dataframe as an Excel file and triggers download.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The dataframe to save.\n",
        "    filename (str): The name of the Excel file to save.\n",
        "    \"\"\"\n",
        "    dataframe.to_excel(filename, index=False)\n",
        "    files.download(filename)\n",
        "    print(f\"{filename} saved and ready for download.\")\n",
        "\n",
        "# Saving and downloading each dataframe as an Excel file\n",
        "save_and_download(df_ciluba_sentences, 'ciluba_sentences.xlsx')\n",
        "save_and_download(df_french_sentences, 'french_sentences.xlsx')\n",
        "save_and_download(df_english_sentences, 'english_sentences.xlsx')\n",
        "save_and_download(df_afrikaans_sentences, 'afrikaans_sentences.xlsx')\n",
        "save_and_download(df_zulu_sentences, 'zulu_sentences.xlsx')\n",
        "save_and_download(df_sepedi_sentences, 'sepedi_sentences.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "qeCKq6qoQPFF",
        "outputId": "9e04c560-b9d1-49f1-8b16-212b6bf346a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8920679f-a422-4c90-b19b-565f6c4e069c\", \"ciluba_sentences.xlsx\", 92050)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciluba_sentences.xlsx saved and ready for download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c57634d-01ac-4728-96f7-9631e8697972\", \"french_sentences.xlsx\", 89327)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "french_sentences.xlsx saved and ready for download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5d6cf083-5256-4c4c-8b9b-0bda20c1d4aa\", \"english_sentences.xlsx\", 85808)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_sentences.xlsx saved and ready for download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0302ef56-4cbd-41c4-955e-5ee9aa7aee24\", \"afrikaans_sentences.xlsx\", 91051)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "afrikaans_sentences.xlsx saved and ready for download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d295b775-b34b-401e-a707-0ea8ad88f461\", \"zulu_sentences.xlsx\", 95457)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zulu_sentences.xlsx saved and ready for download.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_sepedi_sentences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-89c6042848b1>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msave_and_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_afrikaans_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'afrikaans_sentences.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msave_and_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_zulu_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zulu_sentences.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msave_and_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sepedi_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sepedi_sentences.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_sepedi_sentences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/corrected_lexicon.xlsx'\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data from the first sheet\n",
        "df = pd.read_excel(excel_data)\n",
        "\n",
        "# Extracting the relevant columns for each language to create individual dataframes\n",
        "languages = ['CILUBA', 'FRANCAIS', 'ENGLISH', 'AFRIKAANS', 'ZULU', 'SEPEDI']\n",
        "\n",
        "# Creating individual dataframes for each language along with their nature\n",
        "df_ciluba = df[['CILUBA', 'NATURE']].dropna().rename(columns={'CILUBA': 'word'})\n",
        "df_french = df[['FRANCAIS', 'NATURE']].dropna().rename(columns={'FRANCAIS': 'word'})\n",
        "df_english = df[['ENGLISH', 'NATURE']].dropna().rename(columns={'ENGLISH': 'word'})\n",
        "df_afrikaans = df[['AFRIKAANS', 'NATURE']].dropna().rename(columns={'AFRIKAANS': 'word'})\n",
        "df_zulu = df[['ZULU', 'NATURE']].dropna().rename(columns={'ZULU': 'word'})\n",
        "df_sepedi = df[['Sepedi', 'NATURE']].dropna().rename(columns={'SEPEDI': 'word'})\n",
        "\n",
        "# Function to create random sentences\n",
        "def create_random_sentences(df, language_name):\n",
        "    \"\"\"\n",
        "    This function takes a dataframe of words and their nature and creates a new dataframe with randomized sentences.\n",
        "    The sentences consist of the word in the current row and 4 randomly selected words from the dataframe.\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "\n",
        "    # Convert the 'word' column to a list for random selection\n",
        "    words_list = df['word'].str.strip().tolist()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Get the current word\n",
        "        current_word = row['word'].strip()\n",
        "\n",
        "        # Randomly select 4 other words from the list\n",
        "        random_words = random.choices(words_list, k=4)\n",
        "\n",
        "        # Create the sentence\n",
        "        sentence = ' '.join([current_word] + random_words)\n",
        "\n",
        "        # Append the sentence and source language to the list\n",
        "        sentences.append({'source_language': language_name, 'sentence': sentence})\n",
        "\n",
        "    # Create a new dataframe from the list of sentences\n",
        "    sentences_df = pd.DataFrame(sentences)\n",
        "    return sentences_df\n",
        "\n",
        "# Creating the randomized sentence dataframe for each language, including Sepedi\n",
        "df_ciluba_sentences = create_random_sentences(df_ciluba, 'CILUBA')\n",
        "df_french_sentences = create_random_sentences(df_french, 'FRENCH')\n",
        "df_english_sentences = create_random_sentences(df_english, 'ENGLISH')\n",
        "df_afrikaans_sentences = create_random_sentences(df_afrikaans, 'AFRIKAANS')\n",
        "df_zulu_sentences = create_random_sentences(df_zulu, 'ZULU')\n",
        "df_sepedi_sentences = create_random_sentences(df_sepedi, 'Sepedi')\n",
        "\n",
        "# Display the first 5 rows of each dataframe\n",
        "print(df_ciluba_sentences.head(5))\n",
        "print(df_french_sentences.head(5))\n",
        "print(df_english_sentences.head(5))\n",
        "print(df_afrikaans_sentences.head(5))\n",
        "print(df_zulu_sentences.head(5))\n",
        "print(df_sepedi_sentences.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "NR_QJOBKPcIE",
        "outputId": "733aae8f-c7ab-4844-ada6-6c2d6f371353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'word'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'word'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4bd123bf475b>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdf_afrikaans_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_afrikaans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AFRIKAANS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mdf_zulu_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_zulu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZULU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mdf_sepedi_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sepedi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sepedi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Display the first 5 rows of each dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4bd123bf475b>\u001b[0m in \u001b[0;36mcreate_random_sentences\u001b[0;34m(df, language_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Convert the 'word' column to a list for random selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mwords_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'word'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Function to save each dataframe as an Excel file\n",
        "# def save_dataframe_as_excel(dataframe, filename):\n",
        "#     \"\"\"\n",
        "#     Saves a given dataframe as an Excel file.\n",
        "\n",
        "#     Parameters:\n",
        "#     dataframe (pd.DataFrame): The dataframe to save.\n",
        "#     filename (str): The name of the Excel file to save.\n",
        "#     \"\"\"\n",
        "#     dataframe.to_excel(filename, index=False)\n",
        "#     print(f\"{filename} saved successfully.\")\n",
        "\n",
        "# # Saving each dataframe\n",
        "# save_dataframe_as_excel(df_ciluba_sentences, 'ciluba_sentences.xlsx')\n",
        "# save_dataframe_as_excel(df_french_sentences, 'french_sentences.xlsx')\n",
        "# save_dataframe_as_excel(df_english_sentences, 'english_sentences.xlsx')\n",
        "# save_dataframe_as_excel(df_afrikaans_sentences, 'afrikaans_sentences.xlsx')\n",
        "# save_dataframe_as_excel(df_zulu_sentences, 'zulu_sentences.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjToHxn_jC_l",
        "outputId": "fc06028e-802c-4b2c-eb1b-9795fffde3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciluba_sentences.xlsx saved successfully.\n",
            "french_sentences.xlsx saved successfully.\n",
            "english_sentences.xlsx saved successfully.\n",
            "afrikaans_sentences.xlsx saved successfully.\n",
            "zulu_sentences.xlsx saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a testing corpus for sentiment analysis**"
      ],
      "metadata": {
        "id": "90CoitjQxw2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import random\n",
        "\n",
        "# # Load the Excel file\n",
        "# file_path = 'corrected_lexicon.xlsx'\n",
        "# excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# # Load the data from the first sheet\n",
        "# df = pd.read_excel(excel_data, sheet_name='Sheet1')\n",
        "\n",
        "# # Updating the dataframes to include the \"SCORE\" column and remove the \"NATURE\" column for each language\n",
        "# df_ciluba = df[['CILUBA', 'SCORE']].dropna().rename(columns={'CILUBA': 'word'})\n",
        "# df_french = df[['FRANCAIS', 'SCORE']].dropna().rename(columns={'FRANCAIS': 'word'})\n",
        "# df_english = df[['ENGLISH', 'SCORE']].dropna().rename(columns={'ENGLISH': 'word'})\n",
        "# df_afrikaans = df[['AFRIKAANS', 'SCORE']].dropna().rename(columns={'AFRIKAANS': 'word'})\n",
        "# df_zulu = df[['ZULU', 'SCORE']].dropna().rename(columns={'ZULU': 'word'})\n",
        "\n",
        "# def create_random_sentences_with_scores(df, language_name):\n",
        "#     \"\"\"\n",
        "#     This function takes a dataframe of words and their scores and creates a new dataframe with randomized sentences.\n",
        "#     The sentences consist of the word in the current row and 4 randomly selected words from the dataframe.\n",
        "#     Additionally, it calculates the total score and sentiment for each sentence.\n",
        "#     \"\"\"\n",
        "#     sentences = []\n",
        "\n",
        "#     # Convert the 'word' and 'score' columns to lists for random selection\n",
        "#     words_list = df['word'].str.strip().tolist()\n",
        "#     scores_list = df['SCORE'].tolist()\n",
        "\n",
        "#     for index, row in df.iterrows():\n",
        "#         # Get the current word and its score\n",
        "#         current_word = row['word'].strip()\n",
        "#         current_score = row['SCORE']\n",
        "\n",
        "#         # Randomly select 4 other words and their scores\n",
        "#         random_indices = random.choices(range(len(words_list)), k=4)\n",
        "#         random_words = [words_list[i] for i in random_indices]\n",
        "#         random_scores = [scores_list[i] for i in random_indices]\n",
        "\n",
        "#         # Calculate the total score\n",
        "#         total_score = current_score + sum(random_scores)\n",
        "\n",
        "#         # Determine the sentiment based on the total score\n",
        "#         if total_score > 0.05:\n",
        "#             sentiment = \"positive\"\n",
        "#         elif total_score < 0.05:\n",
        "#             sentiment = \"negative\"\n",
        "#         else:\n",
        "#             sentiment = \"neutral\"\n",
        "\n",
        "#         # Create the sentence\n",
        "#         sentence = ' '.join([current_word] + random_words)\n",
        "\n",
        "#         # Append the sentence, score, and sentiment to the list\n",
        "#         sentences.append({\n",
        "#             'source_language': language_name,\n",
        "#             'sentence': sentence,\n",
        "#             'score': total_score,\n",
        "#             'sentiment': sentiment\n",
        "#         })\n",
        "\n",
        "#     # Create a new dataframe from the list of sentences\n",
        "#     sentences_df = pd.DataFrame(sentences)\n",
        "#     return sentences_df\n",
        "\n",
        "# # Creating the updated randomized sentence dataframe for each language\n",
        "# df_ciluba_sentences = create_random_sentences_with_scores(df_ciluba, 'CILUBA')\n",
        "# df_french_sentences = create_random_sentences_with_scores(df_french, 'FRENCH')\n",
        "# df_english_sentences = create_random_sentences_with_scores(df_english, 'ENGLISH')\n",
        "# df_afrikaans_sentences = create_random_sentences_with_scores(df_afrikaans, 'AFRIKAANS')\n",
        "# df_zulu_sentences = create_random_sentences_with_scores(df_zulu, 'ZULU')\n",
        "\n",
        "# # Function to save each dataframe as an Excel file\n",
        "# def save_dataframe_as_excel(dataframe, filename):\n",
        "#     \"\"\"\n",
        "#     Saves a given dataframe as an Excel file.\n",
        "\n",
        "#     Parameters:\n",
        "#     dataframe (pd.DataFrame): The dataframe to save.\n",
        "#     filename (str): The name of the Excel file to save.\n",
        "#     \"\"\"\n",
        "#     dataframe.to_excel(filename, index=False)\n",
        "#     print(f\"{filename} saved successfully.\")\n",
        "\n",
        "# # Saving each dataframe as an Excel file\n",
        "# save_dataframe_as_excel(df_ciluba_sentences, 'ciluba_sentences_sa.xlsx')\n",
        "# save_dataframe_as_excel(df_french_sentences, 'french_sentences_sa.xlsx')\n",
        "# save_dataframe_as_excel(df_english_sentences, 'english_sentences_sa.xlsx')\n",
        "# save_dataframe_as_excel(df_afrikaans_sentences, 'afrikaans_sentences_sa.xlsx')\n",
        "# save_dataframe_as_excel(df_zulu_sentences, 'zulu_sentences_sa.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLGCgD01xQeQ",
        "outputId": "b628ff3b-04d8-4b46-b5c9-5bcb80e9b2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciluba_sentences_sa.xlsx saved successfully.\n",
            "french_sentences_sa.xlsx saved successfully.\n",
            "english_sentences_sa.xlsx saved successfully.\n",
            "afrikaans_sentences_sa.xlsx saved successfully.\n",
            "zulu_sentences_sa.xlsx saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QU8aZOYLBF98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}